# LangSmith (observability) — set true for traces; helps debug multi-agent runs and latency
LANGCHAIN_TRACING_V2=true
# API key from https://smith.langchain.com (or your LangSmith host)
LANGCHAIN_API_KEY=
# Optional: project name in LangSmith for grouping runs (default: default)
# LANGCHAIN_PROJECT=automaton-auditor

# Groq (free tier) — Judges; optional RepoInvestigator summary
GROQ_API_KEY=
# Judge model (default llama-3.3-70b-versatile). If rate limited try llama-3.1-8b-instant
# GROQ_JUDGE_MODEL=llama-3.3-70b-versatile
# Use Gemini for judges: JUDGE_PROVIDER=google (requires GOOGLE_API_KEY)
# JUDGE_PROVIDER=groq

# Google AI Studio (Gemini) — DocAnalyst, VisionInspector; optional Judges when JUDGE_PROVIDER=google or Groq 429
GOOGLE_API_KEY=
# Optional: Gemini model (default gemini-2.0-flash). If 404 try gemini-1.5-flash-latest or gemini-1.5-flash-002
# GOOGLE_GEMINI_MODEL=gemini-2.0-flash

# Optional override for local testing (default stack does not require OpenAI)
# OPENAI_API_KEY=
